{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "8c7f1e9f-aa86-4d9e-b35a-de90e3c09586",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1184,
    "execution_start": 1651706966826,
    "source_hash": "fc719037",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The goal of this notebook is to lay the foundation\n",
    "# for two types of supervised machine learning classifiers.\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "80a86a872f8c4cf3b60d2ae311e9f85d",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1651706968017,
    "source_hash": "61779d5b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This pipeline starts from the point we have a pandas dataframe containing song attributes and genre\n",
    "## step 1: break the data into training and test data\n",
    "## step 2: generate a classifier using the training data\n",
    "## step 3: test the performance using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0: Filter Out Unneeded Cols\n",
    "def condition_raw_data(raw_df):\n",
    "    \"\"\"\n",
    "    Consume a dataframe\n",
    "\n",
    "    Return a DF with the musical attributes and genre columns only\n",
    "    \"\"\"\n",
    "    # rename artist genres to be called genre\n",
    "    raw_df.rename(columns={'artist_genres': 'genre'}, inplace=True)\n",
    "    # features and y val cols.\n",
    "    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo', 'time_signature',\n",
    "                'duration_ms', 'genre'\n",
    "       ]\n",
    "    # update key features based on feature importance\n",
    "    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo',\n",
    "                'duration_ms', 'genre'\n",
    "       ]\n",
    "    # remove unneccessary cols\n",
    "    raw_df = raw_df[required_cols]\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step N: Create a function that will clean the genres.\n",
    "\n",
    "def calculate_popular_genre(track_df, max_num_genres = 10):\n",
    "    \"\"\"\n",
    "    Read a series of genre tuples\n",
    "    Calculate the most frequent genre\n",
    "\n",
    "    return an updated dataframe with one genre\n",
    "    \"\"\"\n",
    "    # create a counter to collect genre names\n",
    "    # remove rows missing genre\n",
    "    track_df = track_df.loc[track_df['genre'].apply(len)>0,:]\n",
    "    genre_counter = Counter()\n",
    "    for genres in track_df['genre']:\n",
    "        for genre in genres:\n",
    "            # split by space to help eliminate sub categories of major genres\n",
    "            split_genre = genre.split(' ')\n",
    "            # fill the counter with the genres\n",
    "            genre_counter.update(split_genre)\n",
    "    # create a list to hold the most popular genre for each artist\n",
    "    top_genres = []\n",
    "    # convert the counter to a dict so that we can look up the score\n",
    "    genre_score = dict(genre_counter)\n",
    "    for genres in track_df['genre']:\n",
    "        # initialize the score and genre to None\n",
    "        temp_score = 0\n",
    "        temp_genre = None\n",
    "        for genre in genres:\n",
    "            genre = genre.split(' ')\n",
    "            for sub_genre in genre:\n",
    "                # calculate score by looking it up in the dictionary\n",
    "                eval_score = genre_score[sub_genre]\n",
    "                if eval_score > temp_score:\n",
    "                    temp_score = eval_score\n",
    "                    temp_genre = sub_genre\n",
    "        top_genres.append(temp_genre)\n",
    "    track_df['genre'] = top_genres\n",
    "    # Create a new counter and filter\n",
    "    filt_genres = Counter(top_genres)\n",
    "    cut_off_genres = filt_genres.most_common(max_num_genres)\n",
    "    included_genres = list(zip(*cut_off_genres))[0]\n",
    "    # filter out low frequency genres\n",
    "    track_df = track_df[track_df['genre'].isin(included_genres)]\n",
    "    return track_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "7449a068dbb14ff5bc0980e4d734328b",
    "deepnote_cell_height": 369,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1651706968027,
    "source_hash": "192ce9f9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Step 1: Break the data into a training and a test set\n",
    "def generate_train_test(tracks_df, random_val=42, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        a dataframe containing song attributes and genre.\n",
    "        random val for repeatability\n",
    "        split_ratio = decimal pct of samples to use for training.\n",
    "    returns:\n",
    "        two dataframes train_df and test_df\n",
    "    \"\"\"\n",
    "    # step 1 shuffle the df\n",
    "    temp_df = tracks_df.sample(random_state=random_val, frac=1.0)\n",
    "    temp_df.reset_index(inplace=True, drop=True)\n",
    "    # establish a number to split the frame at.\n",
    "    num_train_samples = int(split_ratio*len(tracks_df))\n",
    "    # split the DF into two sets train and test\n",
    "    return np.split(temp_df, [num_train_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "24fc39936d2c4ca1b0339567b69ebad2",
    "deepnote_cell_height": 423,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1651706968043,
    "source_hash": "6c17d69a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: train a classifier using the training set\n",
    "\n",
    "def train_logistic_regression(train_df, random_val=42, data_type='spotify'):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        A dataframe of training data\n",
    "        A random value for repeatability\n",
    "\n",
    "    returns:\n",
    "        a trained classifier.\n",
    "    \"\"\"\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "        \n",
    "\n",
    "    # Step 2 create the classifier\n",
    "    clf = LogisticRegression(random_state=random_val, solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n",
    "    \n",
    "    # fit the classifier\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "cell_id": "946fec17732c4ecea704229868008c5c",
    "deepnote_cell_height": 390,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: train a random forest classifier\n",
    "def train_random_forest(train_df, random_val=42):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        A dataframe of training data\n",
    "        A random value for repeatability\n",
    "\n",
    "    returns:\n",
    "        a trained classifier.\n",
    "    \"\"\"\n",
    "    # Step 1 create X and y\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "\n",
    "    # Step 2 create the classifier\n",
    "    clf = RandomForestClassifier(random_state=random_val, n_estimators=1000, max_features='sqrt', criterion='entropy', max_depth=30)\n",
    "    #clf = RandomForestClassifier(random_state=random_val)\n",
    "    \n",
    "    # fit the classifier\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a support vector machine to assist with the high dimensionality of the data\n",
    "\n",
    "# Step 3: train a SVC classifier\n",
    "def train_svm(train_df, random_val=42):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        A dataframe of training data\n",
    "        A random value for repeatability\n",
    "\n",
    "    returns:\n",
    "        a trained classifier.\n",
    "    \"\"\"\n",
    "    # Step 1 create X and y\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "\n",
    "    # Step 2 create the classifier\n",
    "    clf = make_pipeline(StandardScaler(), SVC(random_state=random_val))\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    # fit the classifier\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "9473997adc2a4c758e3950c3aa61aa7b",
    "deepnote_cell_height": 405,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32,
    "execution_start": 1651706968057,
    "owner_user_id": "7cc5a0be-055b-40bf-ac0a-3dbaf638d522",
    "source_hash": "d5159fb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: test the classifiers\n",
    "\n",
    "def test_clf_model(clf, test_df):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        testing set\n",
    "        clf\n",
    "    returns:\n",
    "        f1 score\n",
    "    \"\"\"\n",
    "    # step 1 create an X_test and y_test\n",
    "    X_test = test_df[[col for col in test_df.columns if col != 'genre']]\n",
    "    y_test = test_df['genre']\n",
    "\n",
    "    # step 2 predict the genre for the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # step 3 calculate the average F1 score for all classes\n",
    "    return f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=659c715d-e2b5-478e-9116-4d32a5174810' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy classifier for comparison\n",
    "\n",
    "def create_dummy(train_df, random_val=42, data_type='spotify'):\n",
    "    \"\"\"\n",
    "    Train a uniform dummy classifier for performance evaluation\n",
    "    \"\"\"\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "\n",
    "    random_clf = DummyClassifier(strategy='uniform', random_state=random_val)\n",
    "    random_clf.fit(X, y)\n",
    "    return random_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: 0.607946576413531\n",
      "logistic regression: 0.5041775923096872\n",
      "Support Vector Classifier: 0.5514640837980559\n",
      "dummy classifier: 0.06997919095663456\n"
     ]
    }
   ],
   "source": [
    "# development cell for integrating all functions together.\n",
    "raw_df = pd.read_csv('dev_data_2.csv')\n",
    "train, test = generate_train_test(raw_df, 42, 0.8)\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "svc_clf = train_svm(train)\n",
    "dum_clf = create_dummy(train)\n",
    "lr_score = test_clf_model(lr_clf, test)\n",
    "rf_score = test_clf_model(rf_clf, test)\n",
    "svc_score = test_clf_model(svc_clf, test)\n",
    "dum_score = test_clf_model(dum_clf, test)\n",
    "print(f'random forest: {rf_score}')\n",
    "print(f'logistic regression: {lr_score}')\n",
    "print(f'Support Vector Classifier: {svc_score}')\n",
    "print(f'dummy classifier: {dum_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: 0.5964177851134373\n",
      "logistic regression: 0.3117137764196588\n",
      "Support Vector Classifier: 0.5151960784313726\n",
      "dummy classifier: 0.13917133026572154\n"
     ]
    }
   ],
   "source": [
    "# development cell for evaluating performance with raw api data.\n",
    "raw_df = pd.read_csv('../raw_spotify_data/raw_spotify_data.csv', converters={\"artist_genres\": ast.literal_eval})\n",
    "raw_df = condition_raw_data(raw_df)\n",
    "clean_df = calculate_popular_genre(raw_df, 5)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "svc_clf = train_svm(train)\n",
    "dum_clf = create_dummy(train)\n",
    "lr_score = test_clf_model(lr_clf, test)\n",
    "rf_score = test_clf_model(rf_clf, test)\n",
    "svc_score = test_clf_model(svc_clf, test)\n",
    "dum_score = test_clf_model(dum_clf, test)\n",
    "print(f'random forest: {rf_score}')\n",
    "print(f'logistic regression: {lr_score}')\n",
    "print(f'Support Vector Classifier: {svc_score}')\n",
    "print(f'dummy classifier: {dum_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: 0.731493576362299\n",
      "logistic regression: 0.661349113003719\n",
      "Support Vector Classifier: 0.6741944436861882\n",
      "dummy classifier: 0.1348860045008973\n"
     ]
    }
   ],
   "source": [
    "# supervised training using draw_spotify_data_v2\n",
    "# development cell for evaluating performance with raw api data.\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "#clean_df = clean_df[clean_df['genre']!='alt-rock']\n",
    "#clean_df = clean_df[clean_df['genre']!='classical']\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "svc_clf = train_svm(train)\n",
    "dum_clf = create_dummy(train)\n",
    "lr_score = test_clf_model(lr_clf, test)\n",
    "rf_score = test_clf_model(rf_clf, test)\n",
    "svc_score = test_clf_model(svc_clf, test)\n",
    "dum_score = test_clf_model(dum_clf, test)\n",
    "print(f'random forest: {rf_score}')\n",
    "print(f'logistic regression: {lr_score}')\n",
    "print(f'Support Vector Classifier: {svc_score}')\n",
    "print(f'dummy classifier: {dum_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# goal apply PCA to the data set. Evaluate impact on F1\n",
    "def apply_pca(train_df, test_df, n_dim = 2):\n",
    "    \"\"\"\n",
    "    read in the training data for a dataframe\n",
    "    apply dimmensionality reduction\n",
    "\n",
    "    return modified train and test sets\n",
    "    \"\"\"\n",
    "    # start off with stock settings\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    train_df.reset_index(inplace=True, drop=True)\n",
    "    test_df.reset_index(inplace=True, drop=True)\n",
    "    X_cols = [col for col in train_df.columns if col != 'genre']\n",
    "\n",
    "    myScaler = StandardScaler()\n",
    "    X_train = myScaler.fit_transform(train_df[X_cols])\n",
    "    X_test = myScaler.transform(test_df[X_cols])\n",
    "    # only use the training data to fit the pca model\n",
    "    pca.fit(X_train)\n",
    "    # lesson learned here you need to reset the index so that pandas merges the labels\n",
    "    # back in correctly\n",
    "    pca_train_df = pd.DataFrame(pca.transform(X_train))\n",
    "    pca_train_df['genre'] = train_df['genre']\n",
    "\n",
    "    pca_test_df = pd.DataFrame(pca.transform(X_test))\n",
    "    pca_test_df['genre'] = test_df['genre']\n",
    "    return pca_train_df, pca_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: 0.6721235924353675\n",
      "logistic regression: 0.6428536268802836\n",
      "dummy classifier: 0.1348860045008973\n"
     ]
    }
   ],
   "source": [
    "# implement pca function\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "train, test = apply_pca(train, test, 10)\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "dum_clf = create_dummy(train)\n",
    "lr_score = test_clf_model(lr_clf, test)\n",
    "rf_score = test_clf_model(rf_clf, test)\n",
    "dum_score = test_clf_model(dum_clf, test)\n",
    "print(f'random forest: {rf_score}')\n",
    "print(f'logistic regression: {lr_score}')\n",
    "print(f'dummy classifier: {dum_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a TFIDF vectorizer to the lyrics.\n",
    "def train_tfidf_vectorizer(train, test, random_val = 42):\n",
    "    \"\"\"\n",
    "    read in a train and test set\n",
    "    return train and test in vectorizer form\n",
    "    \"\"\"\n",
    "    X_train = train['lyric_raw']\n",
    "    y_train = train['genre'].values\n",
    "    X_test = test['lyric_raw'].fillna(value=' ')\n",
    "    X_train.fillna(value=' ', inplace=True)\n",
    "    vectorizer = TfidfVectorizer(min_df=50, stop_words='english', ngram_range=(1,2))\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    y_test = test['genre'].values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def lyrics_random_forest(X_train, y_train, random_state=42):\n",
    "    \"\"\"\n",
    "    read in X_train and y_train\n",
    "    return clf\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=1000, random_state=random_state, max_features=30, max_depth=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def lyrics_logistic_reg(X_train, y_train, random_val=42):\n",
    "    \"\"\"\n",
    "    train a logistic regression classifier\n",
    "    return clf\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(random_state=random_val, solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "def evaluate_lyrics_clf(clf, X_test, y_test):\n",
    "    \"\"\"\n",
    "    predict X_test\n",
    "    return F1 score\n",
    "    \"\"\"\n",
    "    preds = clf.predict(X_test)\n",
    "    return f1_score(y_test, preds, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296232313033973"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\n",
    "lyrics_df = lyrics_df[['lyric_raw', 'genre']]\n",
    "#lyrics_df = lyrics_df[lyrics_df['genre']!='classical']\n",
    "#lyrics_df = lyrics_df[lyrics_df['genre']!='edm']\n",
    "train, test = generate_train_test(lyrics_df)\n",
    "X_train, y_train, X_test, y_test = train_tfidf_vectorizer(train, test)\n",
    "lyrics_forest_clf = lyrics_random_forest(X_train, y_train)\n",
    "evaluate_lyrics_clf(lyrics_forest_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the goal of this cell is to train a model using lyrics AND using song attributes\n",
    "def lyric_attribute_train_test(all_df):\n",
    "    \"\"\"\n",
    "    read in a dataframe\n",
    "    return train and test data\n",
    "    \"\"\"\n",
    "    # list of columns to throw away\n",
    "    blacklist = ['artist_name_y', 'track_name_y','artist_name_x', 'artist_id', 'track_name_x','track_id', 'uri', 'track_href', 'analysis_url', 'type', 'lyric_clean']\n",
    "    all_df = all_df[[col for col in all_df.columns if col not in blacklist]]\n",
    "    train, test = generate_train_test(all_df)\n",
    "    # get vectorized lyrics:\n",
    "    X_train, y_train, X_test, y_test = train_tfidf_vectorizer(train, test)\n",
    "    # remove raw lyrics\n",
    "    del train['lyric_raw'] \n",
    "    del test['lyric_raw']\n",
    "    del train['genre']\n",
    "    del test['genre']\n",
    "    X_train = hstack([X_train, train.values])\n",
    "    X_test = hstack([X_test, test.values])\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.822337286144033"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\n",
    "#all_df = all_df[all_df['genre']!='alt-rock']\n",
    "X_train, y_train, X_test, y_test = lyric_attribute_train_test(all_df)\n",
    "lyrics_forest_clf = lyrics_random_forest(X_train, y_train)\n",
    "evaluate_lyrics_clf(lyrics_forest_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start grid search for model tuning\n",
    "temp_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'max_depth' : [30, 50],\n",
    "    #'min_samples_leaf' : [1],\n",
    "    'n_estimators' : [1000, 1500, 2000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    #'min_samples_split' : [2, 4, 10],\n",
    "    #'min_weight_fraction_leaf' : [0.0, 0.05],\n",
    "    'max_features' : [2, 'sqrt', 4, 5],\n",
    "    #'max_samples' : [0.9999]\n",
    "}\n",
    "gSearch = GridSearchCV(temp_clf, param_grid=param_grid, scoring='accuracy', n_jobs=-1, verbose=1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [30, 50], 'max_features': ['sqrt', 4, 5],\n",
       "                         'n_estimators': [1000, 1500, 2000]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "X_train = train[[col for col in train.columns if col != 'genre']]\n",
    "y_train = train['genre']\n",
    "gSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71375"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find feature importance\n",
    "gSearch.best_score_\n",
    "my_feature_importance = gSearch.best_estimator_.feature_importances_\n",
    "features = [col for col in train.columns if col != 'genre']\n",
    "sorted(list(zip(features, my_feature_importance)), key = lambda x: -x[1])\n",
    "gSearch.best_estimator_\n",
    "#gSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start grid search for model tuning for lyrics too.\n",
    "temp_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'max_depth' : [100, 125, 150, 200],\n",
    "    #'min_samples_leaf' : [1],\n",
    "    'n_estimators' : [1000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    #'min_samples_split' : [2, 4, 10],\n",
    "    #'min_weight_fraction_leaf' : [0.0, 0.05],\n",
    "    'max_features' : [30],\n",
    "    #'max_samples' : [0.9999]\n",
    "}\n",
    "gSearch = GridSearchCV(temp_clf, param_grid=param_grid, scoring='accuracy', n_jobs=-1, verbose=1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [100, 125, 150, 200],\n",
       "                         'max_features': [30], 'n_estimators': [1000]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\n",
    "lyrics_df = lyrics_df[['lyric_raw', 'genre']]\n",
    "train, test = generate_train_test(lyrics_df)\n",
    "X_train, y_train, X_test, y_test = train_tfidf_vectorizer(train, test)\n",
    "gSearch.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 30,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gSearch.best_estimator_\n",
    "gSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mean song for each genre\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "# step 1 group by genre\n",
    "mean_track_df = train.groupby('genre').mean().reset_index()\n",
    "# calculate similatrity score \n",
    "# start failure analysis for logistic regression and random forest\n",
    "\n",
    "# load in the raw data\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "# train models\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "\n",
    "X_test = test[[col for col in test.columns if col != 'genre']]\n",
    "y_test = test['genre']\n",
    "# predict\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "failure_df = pd.DataFrame()\n",
    "failure_df['true_y'] = y_test\n",
    "failure_df['pred_y'] = y_pred_rf\n",
    "failure_df[[col for col in test.columns if col != 'genre']] = X_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, 'alt-rock']\n",
      "94 92\n",
      "[False, 'classical']\n",
      "0 185\n",
      "[True, 'country']\n",
      "55 152\n",
      "[True, 'edm']\n",
      "75 133\n",
      "[True, 'heavy-metal']\n",
      "33 170\n",
      "[False, 'hip-hop']\n",
      "61 149\n",
      "[True, 'latin']\n",
      "58 143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024, 376)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_to_collect = ('alt-rock','classical', 'country',\n",
    "                       'edm', 'heavy-metal',  'hip-hop',\n",
    "                       'latin')\n",
    "required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo',\n",
    "                'duration_ms'\n",
    "            ]\n",
    "failure_df['results'] = (failure_df['pred_y'] == failure_df['true_y'])\n",
    "failure_df\n",
    "for genre in genres_to_collect:\n",
    "    tempDF = failure_df[failure_df['true_y']==genre]\n",
    "    tempMean = mean_track_df[mean_track_df['genre']==genre]\n",
    "    temp_sim = euclidean_distances(tempMean[required_cols], tempDF[required_cols])\n",
    "    sim_results = list(zip(temp_sim.flatten(), tempDF['results']))\n",
    "    failures = [dis for (dis, status) in sim_results if status == False]\n",
    "    passes = [dis for (dis, status) in sim_results if status == True]\n",
    "    print([(np.mean(failures) > np.mean(passes)), genre])\n",
    "    print(len(failures), len(passes))\n",
    "\n",
    "len(failure_df[failure_df['results']==True]), len(failure_df[failure_df['results']==False])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\n",
    "#all_df = all_df[all_df['genre']!='alt-rock']\n",
    "X_train, y_train, X_test, y_test = lyric_attribute_train_test(all_df)\n",
    "rf_clf = lyrics_random_forest(X_train, y_train)\n",
    "\n",
    "\n",
    "# train models\n",
    "# predict\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "failure_df = pd.DataFrame()\n",
    "failure_df['true_y'] = y_test\n",
    "failure_df['pred_y'] = y_pred_rf\n",
    "#failure_df[[col for col in test.columns if col != 'genre']] = X_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt-rock']\n",
      "81 105\n",
      "['classical']\n",
      "0 191\n",
      "['country']\n",
      "25 176\n",
      "['edm']\n",
      "64 137\n",
      "['heavy-metal']\n",
      "28 173\n",
      "['hip-hop']\n",
      "23 178\n",
      "['latin']\n",
      "21 180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1162, 248)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_to_collect = ('alt-rock','classical', 'country',\n",
    "                       'edm', 'heavy-metal',  'hip-hop',\n",
    "                       'latin')\n",
    "required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo',\n",
    "                'duration_ms'\n",
    "            ]\n",
    "failure_df['results'] = (failure_df['pred_y'] == failure_df['true_y'])\n",
    "failure_df\n",
    "for genre in genres_to_collect:\n",
    "    tempDF = failure_df[failure_df['true_y']==genre]\n",
    "    sim_results = list(zip(temp_sim.flatten(), tempDF['results']))\n",
    "    failures = [dis for (dis, status) in sim_results if status == False]\n",
    "    passes = [dis for (dis, status) in sim_results if status == True]\n",
    "    print([genre])\n",
    "    print(len(failures), len(passes))\n",
    "\n",
    "len(failure_df[failure_df['results']==True]), len(failure_df[failure_df['results']==False])      "
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b78c5f28-75f3-4d35-9c8f-11dd9693160f",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
