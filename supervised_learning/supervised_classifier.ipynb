{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "8c7f1e9f-aa86-4d9e-b35a-de90e3c09586",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1184,
    "execution_start": 1651706966826,
    "source_hash": "fc719037",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 513
   },
   "source": "# The goal of this notebook is to lay the foundation\n# for two types of supervised machine learning classifiers.\nfrom collections import Counter\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport ast\nimport pandas as pd\nimport numpy as np\n\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "80a86a872f8c4cf3b60d2ae311e9f85d",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1651706968017,
    "source_hash": "61779d5b",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 135
   },
   "source": "## This pipeline starts from the point we have a pandas dataframe containing song attributes and genre\n## step 1: break the data into training and test data\n## step 2: generate a classifier using the training data\n## step 3: test the performance using the test data",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-f0d03ca9-205b-4425-af99-e8f921fcd8fe",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 444
   },
   "source": "## Step 0: Filter Out Unneeded Cols\ndef condition_raw_data(raw_df):\n    \"\"\"\n    Consume a dataframe\n\n    Return a DF with the musical attributes and genre columns only\n    \"\"\"\n    # rename artist genres to be called genre\n    raw_df.rename(columns={'artist_genres': 'genre'}, inplace=True)\n    # features and y val cols.\n    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n                'speechiness', 'acousticness', 'instrumentalness', \n                'liveness', 'valence', 'tempo', 'time_signature',\n                'duration_ms', 'genre'\n       ]\n    # remove unneccessary cols\n    raw_df = raw_df[required_cols]\n\n    \n\n    return raw_df\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-5c76733c-1e26-4b2b-a5f1-e050011ece20",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 876
   },
   "source": "## Step N: Create a function that will clean the genres.\n\ndef calculate_popular_genre(track_df, max_num_genres = 10):\n    \"\"\"\n    Read a series of genre tuples\n    Calculate the most frequent genre\n\n    return an updated dataframe with one genre\n    \"\"\"\n    # create a counter to collect genre names\n    # remove rows missing genre\n    track_df = track_df.loc[track_df['genre'].apply(len)>0,:]\n    genre_counter = Counter()\n    for genres in track_df['genre']:\n        for genre in genres:\n            # split by space to help eliminate sub categories of major genres\n            split_genre = genre.split(' ')\n            # fill the counter with the genres\n            genre_counter.update(split_genre)\n    # create a list to hold the most popular genre for each artist\n    top_genres = []\n    # convert the counter to a dict so that we can look up the score\n    genre_score = dict(genre_counter)\n    for genres in track_df['genre']:\n        # initialize the score and genre to None\n        temp_score = 0\n        temp_genre = None\n        for genre in genres:\n            genre = genre.split(' ')\n            for sub_genre in genre:\n                # calculate score by looking it up in the dictionary\n                eval_score = genre_score[sub_genre]\n                if eval_score > temp_score:\n                    temp_score = eval_score\n                    temp_genre = sub_genre\n        top_genres.append(temp_genre)\n    track_df['genre'] = top_genres\n    # Create a new counter and filter\n    filt_genres = Counter(top_genres)\n    cut_off_genres = filt_genres.most_common(max_num_genres)\n    included_genres = list(zip(*cut_off_genres))[0]\n    # filter out low frequency genres\n    track_df = track_df[track_df['genre'].isin(included_genres)]\n    return track_df\n\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7449a068dbb14ff5bc0980e4d734328b",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1651706968027,
    "source_hash": "192ce9f9",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "## Step 1: Break the data into a training and a test set\ndef generate_train_test(tracks_df, random_val=42, split_ratio=0.8):\n    \"\"\"\n    inputs:\n        a dataframe containing song attributes and genre.\n        random val for repeatability\n        split_ratio = decimal pct of samples to use for training.\n    returns:\n        two dataframes train_df and test_df\n    \"\"\"\n    # step 1 shuffle the df\n    temp_df = tracks_df.sample(random_state=random_val, frac=1.0)\n    # establish a number to split the frame at.\n    num_train_samples = int(split_ratio*len(tracks_df))\n    # split the DF into two sets train and test\n    return np.split(temp_df, [num_train_samples])\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "24fc39936d2c4ca1b0339567b69ebad2",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1651706968043,
    "source_hash": "6c17d69a",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 423
   },
   "source": "# Step 2: train a classifier using the training set\n\ndef train_logistic_regression(train_df, random_val=42, data_type='spotify'):\n    \"\"\"\n    inputs:\n        A dataframe of training data\n        A random value for repeatability\n\n    returns:\n        a trained classifier.\n    \"\"\"\n    X = train_df[[col for col in train_df.columns if col != 'genre']]\n    y = train_df['genre']\n        \n\n    # Step 2 create the classifier\n    clf = LogisticRegression(random_state=random_val, solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n    \n    # fit the classifier\n    return clf.fit(X, y)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "946fec17732c4ecea704229868008c5c",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 390
   },
   "source": "# Step 3: train a random forest classifier\ndef train_random_forest(train_df, random_val=42):\n    \"\"\"\n    inputs:\n        A dataframe of training data\n        A random value for repeatability\n\n    returns:\n        a trained classifier.\n    \"\"\"\n    # Step 1 create X and y\n    X = train_df[[col for col in train_df.columns if col != 'genre']]\n    y = train_df['genre']\n\n    # Step 2 create the classifier\n    clf = RandomForestClassifier(random_state=random_val, n_estimators=1000)\n    \n    # fit the classifier\n    return clf.fit(X, y)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-4f9562c8-6dcc-4d0a-89de-d20920cf9e40",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 444
   },
   "source": "# implement a support vector machine to assist with the high dimensionality of the data\n\n# Step 3: train a SVC classifier\ndef train_svm(train_df, random_val=42):\n    \"\"\"\n    inputs:\n        A dataframe of training data\n        A random value for repeatability\n\n    returns:\n        a trained classifier.\n    \"\"\"\n    # Step 1 create X and y\n    X = train_df[[col for col in train_df.columns if col != 'genre']]\n    y = train_df['genre']\n\n    # Step 2 create the classifier\n    clf = make_pipeline(StandardScaler(), SVC(random_state=random_val))\n    clf.fit(X,y)\n    \n    # fit the classifier\n    return clf.fit(X, y)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9473997adc2a4c758e3950c3aa61aa7b",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32,
    "execution_start": 1651706968057,
    "owner_user_id": "7cc5a0be-055b-40bf-ac0a-3dbaf638d522",
    "source_hash": "d5159fb5",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 405
   },
   "source": "# Step 4: test the classifiers\n\ndef test_clf_model(clf, test_df):\n    \"\"\"\n    inputs:\n        testing set\n        clf\n    returns:\n        f1 score\n    \"\"\"\n    # step 1 create an X_test and y_test\n    X_test = test_df[[col for col in test_df.columns if col != 'genre']]\n    y_test = test_df['genre']\n\n    # step 2 predict the genre for the test set\n    y_pred = clf.predict(X_test)\n\n    # step 3 calculate the average F1 score for all classes\n    return f1_score(y_test, y_pred, average='macro')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-1200b404-06a6-4c5e-8202-2143e563be2f",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 264
   },
   "source": "# Create a dummy classifier for comparison\n\ndef create_dummy(train_df, random_val=42, data_type='spotify'):\n    \"\"\"\n    Train a uniform dummy classifier for performance evaluation\n    \"\"\"\n    X = train_df[[col for col in train_df.columns if col != 'genre']]\n    y = train_df['genre']\n\n    random_clf = DummyClassifier(strategy='uniform', random_state=random_val)\n    random_clf.fit(X, y)\n    return random_clf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-b2789887-cfc0-414b-9d89-2da641c26937",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 424.75
   },
   "source": "# development cell for integrating all functions together.\nraw_df = pd.read_csv('dev_data_2.csv')\ntrain, test = generate_train_test(raw_df, 42, 0.8)\nlr_clf = train_logistic_regression(train, 42)\nrf_clf = train_random_forest(train)\nsvc_clf = train_svm(train)\ndum_clf = create_dummy(train)\nlr_score = test_clf_model(lr_clf, test)\nrf_score = test_clf_model(rf_clf, test)\nsvc_score = test_clf_model(svc_clf, test)\ndum_score = test_clf_model(dum_clf, test)\nprint(f'random forest: {rf_score}')\nprint(f'logistic regression: {lr_score}')\nprint(f'Support Vector Classifier: {svc_score}')\nprint(f'dummy classifier: {dum_score}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random forest: 0.6520960462960702\nlogistic regression: 0.5041775923096872\nSupport Vector Classifier: 0.5514640837980559\ndummy classifier: 0.06997919095663456\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-fa6bedb2-f1ad-439f-8298-6806724833bd",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 460.75
   },
   "source": "# development cell for evaluating performance with raw api data.\nraw_df = pd.read_csv('../raw_spotify_data/raw_spotify_data.csv', converters={\"artist_genres\": ast.literal_eval})\nraw_df = condition_raw_data(raw_df)\nclean_df = calculate_popular_genre(raw_df, 5)\ntrain, test = generate_train_test(clean_df, 42, 0.8)\nlr_clf = train_logistic_regression(train, 42)\nrf_clf = train_random_forest(train)\nsvc_clf = train_svm(train)\ndum_clf = create_dummy(train)\nlr_score = test_clf_model(lr_clf, test)\nrf_score = test_clf_model(rf_clf, test)\nsvc_score = test_clf_model(svc_clf, test)\ndum_score = test_clf_model(dum_clf, test)\nprint(f'random forest: {rf_score}')\nprint(f'logistic regression: {lr_score}')\nprint(f'Support Vector Classifier: {svc_score}')\nprint(f'dummy classifier: {dum_score}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random forest: 0.5776054082903398\nlogistic regression: 0.2864425318271472\nSupport Vector Classifier: 0.5119731146046936\ndummy classifier: 0.13917133026572154\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-da2560c3-c4ef-474e-9ce3-e91dacf484f0",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 496.75
   },
   "source": "# supervised training using draw_spotify_data_v2\n# development cell for evaluating performance with raw api data.\nraw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\nclean_df = condition_raw_data(raw_df)\n#clean_df = clean_df[clean_df['genre']!='edm']\n#clean_df = clean_df[clean_df['genre']!='classical']\ntrain, test = generate_train_test(clean_df, 42, 0.8)\nlr_clf = train_logistic_regression(train, 42)\nrf_clf = train_random_forest(train)\nsvc_clf = train_svm(train)\ndum_clf = create_dummy(train)\nlr_score = test_clf_model(lr_clf, test)\nrf_score = test_clf_model(rf_clf, test)\nsvc_score = test_clf_model(svc_clf, test)\ndum_score = test_clf_model(dum_clf, test)\nprint(f'random forest: {rf_score}')\nprint(f'logistic regression: {lr_score}')\nprint(f'Support Vector Classifier: {svc_score}')\nprint(f'dummy classifier: {dum_score}')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random forest: 0.7321047458016763\nlogistic regression: 0.6586439495238977\nSupport Vector Classifier: 0.6809962004780671\ndummy classifier: 0.1348860045008973\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-ae0bee76-6c61-4ded-8236-0afa95ebe4bd",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 552
   },
   "source": "# PCA\n# goal apply PCA to the data set. Evaluate impact on F1\ndef apply_pca(train_df, test_df, n_dim = 2):\n    \"\"\"\n    read in the training data for a dataframe\n    apply dimmensionality reduction\n\n    return modified train and test sets\n    \"\"\"\n    # start off with stock settings\n    pca = PCA(n_components=n_dim)\n    train_df.reset_index(inplace=True, drop=True)\n    test_df.reset_index(inplace=True, drop=True)\n    X_cols = [col for col in train_df.columns if col != 'genre']\n    myScaler = StandardScaler()\n    X_train = myScaler.fit_transform(train_df[X_cols])\n    X_test = myScaler.transform(test_df[X_cols])\n    # only use the training data to fit the pca model\n    pca.fit(X_train)\n    # lesson learned here you need to reset the index so that pandas merges the labels\n    # back in correctly\n    pca_train_df = pd.DataFrame(pca.transform(X_train))\n    pca_train_df['genre'] = train_df['genre']\n\n    pca_test_df = pd.DataFrame(pca.transform(X_test))\n    pca_test_df['genre'] = test_df['genre']\n    return pca_train_df, pca_test_df\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00014-2d700ea2-e0e2-4207-91cb-a62b4b05a4eb",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 496.75
   },
   "source": "# implement pca function\nraw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\nclean_df = condition_raw_data(raw_df)\ntrain, test = generate_train_test(clean_df, 42, 0.8)\ntrain, test = apply_pca(train, test, 2)\nlr_clf = train_logistic_regression(train, 42)\nrf_clf = train_random_forest(train)\nsvc_clf = train_svm(train)\ndum_clf = create_dummy(train)\nlr_score = test_clf_model(lr_clf, test)\nrf_score = test_clf_model(rf_clf, test)\nsvc_score = test_clf_model(svc_clf, test)\ndum_score = test_clf_model(dum_clf, test)\nprint(f'random forest: {rf_score}')\nprint(f'logistic regression: {lr_score}')\nprint(f'Support Vector Classifier: {svc_score}')\nprint(f'dummy classifier: {dum_score}')\n\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "random forest: 0.45408163189558187\nlogistic regression: 0.4240574171251283\nSupport Vector Classifier: 0.4379227806628839\ndummy classifier: 0.1348860045008973\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00015-88f1ed13-b790-413c-814b-08b4c7ee469d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 804
   },
   "source": "# apply a TFIDF vectorizer to the lyrics.\ndef train_tfidf_vectorizer(train, test, random_val = 42):\n    \"\"\"\n    read in a train and test set\n    return train and test in vectorizer form\n    \"\"\"\n    X_train = train['lyric_raw']\n    y_train = train['genre'].values\n    X_test = test['lyric_raw'].fillna(value=' ')\n    X_train.fillna(value=' ', inplace=True)\n    vectorizer = TfidfVectorizer(min_df=100, stop_words='english')\n    X_train = vectorizer.fit_transform(X_train)\n\n    X_test = vectorizer.transform(X_test)\n    y_test = test['genre'].values\n    return X_train, y_train, X_test, y_test\n\ndef lyrics_random_forest(X_train, y_train, random_state=42):\n    \"\"\"\n    read in X_train and y_train\n    return clf\n    \"\"\"\n    clf = RandomForestClassifier(n_estimators=200, random_state=random_state)\n    clf.fit(X_train, y_train)\n    return clf\n\ndef lyrics_logistic_reg(X_train, y_train, random_val=42):\n    \"\"\"\n    train a logistic regression classifier\n    return clf\n    \"\"\"\n    clf = LogisticRegression(random_state=random_val, solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n    clf.fit(X_train, y_train)\n    return clf\ndef evaluate_lyrics_clf(clf, X_test, y_test):\n    \"\"\"\n    predict X_test\n    return F1 score\n    \"\"\"\n    preds = clf.predict(X_test)\n    return f1_score(y_test, preds, average='macro')\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00016-dea5b585-5e00-4875-882f-ce9cda34a1d7",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 208.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "lyrics_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\nlyrics_df = lyrics_df[['lyric_raw', 'genre']]\ntrain, test = generate_train_test(lyrics_df)\nX_train, y_train, X_test, y_test = train_tfidf_vectorizer(train, test)\nlyrics_forest_clf = lyrics_random_forest(X_train, y_train)\nevaluate_lyrics_clf(lyrics_forest_clf, X_test, y_test)",
   "outputs": [
    {
     "data": {
      "text/plain": "0.6398899537539541"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-5955f5f5-3c03-417d-afa6-e3f9898046d3",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 462
   },
   "source": "# the goal of this cell is to train a model using lyrics AND using song attributes\ndef lyric_attribute_train_test(all_df):\n    \"\"\"\n    read in a dataframe\n    return train and test data\n    \"\"\"\n    # list of columns to throw away\n    blacklist = ['artist_name_y', 'track_name_y','artist_name_x', 'artist_id', 'track_name_x','track_id', 'uri', 'track_href', 'analysis_url', 'type', 'lyric_clean']\n    all_df = all_df[[col for col in all_df.columns if col not in blacklist]]\n    train, test = generate_train_test(all_df)\n    # get vectorized lyrics:\n    X_train, y_train, X_test, y_test = train_tfidf_vectorizer(train, test)\n    # remove raw lyrics\n    del train['lyric_raw'] \n    del test['lyric_raw']\n    del train['genre']\n    del test['genre']\n    X_train = hstack([X_train, train.values])\n    X_test = hstack([X_test, test.values])\n    return X_train, y_train, X_test, y_test\n\n\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00018-22700bd8-6e7e-4733-92bf-e2265246a43e",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 172.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "all_df = pd.read_csv('../raw_spotify_data/pure_genre_data_w_clean_lyrics.csv')\nX_train, y_train, X_test, y_test = lyric_attribute_train_test(all_df)\nlyrics_forest_clf = lyrics_random_forest(X_train, y_train)\nevaluate_lyrics_clf(lyrics_forest_clf, X_test, y_test)",
   "outputs": [
    {
     "data": {
      "text/plain": "0.817749878924545"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=659c715d-e2b5-478e-9116-4d32a5174810' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b78c5f28-75f3-4d35-9c8f-11dd9693160f",
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 }
}