{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "8c7f1e9f-aa86-4d9e-b35a-de90e3c09586",
    "deepnote_cell_height": 243,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1184,
    "execution_start": 1651706966826,
    "source_hash": "fc719037",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The goal of this notebook is to lay the foundation\n",
    "# for two types of supervised machine learning classifiers.\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Helper functions for Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "80a86a872f8c4cf3b60d2ae311e9f85d",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1651706968017,
    "source_hash": "61779d5b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This pipeline starts from the point we have a pandas dataframe containing song attributes and genre\n",
    "## step 1: break the data into training and test data\n",
    "## step 2: generate a classifier using the training data\n",
    "## step 3: test the performance using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0: Filter Out Unneeded Cols\n",
    "def condition_raw_data(raw_df):\n",
    "    \"\"\"\n",
    "    Consume a dataframe\n",
    "\n",
    "    Return a DF with the musical attributes and genre columns only\n",
    "    \"\"\"\n",
    "    # rename artist genres to be called genre\n",
    "    raw_df.rename(columns={'artist_genres': 'genre'}, inplace=True)\n",
    "    # features and y val cols.\n",
    "    # this is the original feature set before optimizing.\n",
    "    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo', 'time_signature',\n",
    "                'duration_ms', 'genre'\n",
    "       ]\n",
    "    # update key features based on feature importance\n",
    "    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo',\n",
    "                'duration_ms', 'genre'\n",
    "       ]\n",
    "    # remove unneccessary cols\n",
    "    raw_df = raw_df[required_cols]\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "7449a068dbb14ff5bc0980e4d734328b",
    "deepnote_cell_height": 369,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1651706968027,
    "source_hash": "192ce9f9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Step 1: Break the data into a training and a test set\n",
    "def generate_train_test(tracks_df, random_val=42, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        a dataframe containing song attributes and genre.\n",
    "        random val for repeatability\n",
    "        split_ratio = decimal pct of samples to use for training.\n",
    "    returns:\n",
    "        two dataframes train_df and test_df\n",
    "    \"\"\"\n",
    "    # step 1 shuffle the df\n",
    "    temp_df = tracks_df.sample(random_state=random_val, frac=1.0)\n",
    "    temp_df.reset_index(inplace=True, drop=True)\n",
    "    # establish a number to split the frame at.\n",
    "    num_train_samples = int(split_ratio*len(tracks_df))\n",
    "    # split the DF into two sets train and test\n",
    "    return np.split(temp_df, [num_train_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "24fc39936d2c4ca1b0339567b69ebad2",
    "deepnote_cell_height": 423,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1651706968043,
    "source_hash": "6c17d69a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: train a classifier using the training set\n",
    "def train_logistic_regression(train_df, random_val=42, data_type='spotify'):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        A dataframe of training data\n",
    "        A random value for repeatability\n",
    "\n",
    "    returns:\n",
    "        a trained classifier.\n",
    "    \"\"\"\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "    # Step 2 create the classifier\n",
    "    clf = LogisticRegression(random_state=random_val, solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n",
    "    # fit the classifier\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "cell_id": "946fec17732c4ecea704229868008c5c",
    "deepnote_cell_height": 390,
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: train a random forest classifier\n",
    "def train_random_forest(train_df, random_val=42):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        A dataframe of training data\n",
    "        A random value for repeatability\n",
    "\n",
    "    returns:\n",
    "        a trained classifier.\n",
    "    \"\"\"\n",
    "    # Step 1 create X and y\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "    # Step 2 create the classifier\n",
    "    clf = RandomForestClassifier(random_state=random_val, n_estimators=1000, max_features='sqrt', criterion='entropy', max_depth=30)\n",
    "    # fit the classifier\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "9473997adc2a4c758e3950c3aa61aa7b",
    "deepnote_cell_height": 405,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32,
    "execution_start": 1651706968057,
    "owner_user_id": "7cc5a0be-055b-40bf-ac0a-3dbaf638d522",
    "source_hash": "d5159fb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: test the classifiers\n",
    "def test_clf_model(clf, test_df):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        testing set\n",
    "        clf\n",
    "    returns:\n",
    "        f1 score\n",
    "    \"\"\"\n",
    "    # step 1 create an X_test and y_test\n",
    "    X_test = test_df[[col for col in test_df.columns if col != 'genre']]\n",
    "    y_test = test_df['genre']\n",
    "    # step 2 predict the genre for the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # step 3 calculate the average F1 score for all classes\n",
    "    return f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy classifier for comparison\n",
    "def create_dummy(train_df, random_val=42, data_type='spotify'):\n",
    "    \"\"\"\n",
    "    Train a uniform dummy classifier for performance evaluation\n",
    "    \"\"\"\n",
    "    X = train_df[[col for col in train_df.columns if col != 'genre']]\n",
    "    y = train_df['genre']\n",
    "    random_clf = DummyClassifier(strategy='uniform', random_state=random_val)\n",
    "    random_clf.fit(X, y)\n",
    "    return random_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Model Functions and Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest: 0.731493576362299\n",
      "logistic regression: 0.661349113003719\n",
      "Support Vector Classifier: 0.6741944436861882\n",
      "dummy classifier: 0.1348860045008973\n"
     ]
    }
   ],
   "source": [
    "# supervised training using draw_spotify_data_v3\n",
    "# development cell for evaluating performance with raw api data.\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "lr_clf = train_logistic_regression(train, 42)\n",
    "rf_clf = train_random_forest(train)\n",
    "dum_clf = create_dummy(train)\n",
    "lr_score = test_clf_model(lr_clf, test)\n",
    "rf_score = test_clf_model(rf_clf, test)\n",
    "dum_score = test_clf_model(dum_clf, test)\n",
    "print(f'random forest: {rf_score}')\n",
    "print(f'logistic regression: {lr_score}')\n",
    "print(f'dummy classifier: {dum_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search for Random Forest Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start grid search for model tuning\n",
    "temp_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'max_depth' : [30, 50],\n",
    "    #'min_samples_leaf' : [1],\n",
    "    'n_estimators' : [1000, 1500, 2000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    #'min_samples_split' : [2, 4, 10],\n",
    "    #'min_weight_fraction_leaf' : [0.0, 0.05],\n",
    "    'max_features' : [2, 'sqrt', 4, 5],\n",
    "    #'max_samples' : [0.9999]\n",
    "}\n",
    "gSearch = GridSearchCV(temp_clf, param_grid=param_grid, scoring='accuracy', n_jobs=-1, verbose=1, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [30, 50], 'max_features': ['sqrt', 4, 5],\n",
       "                         'n_estimators': [1000, 1500, 2000]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "X_train = train[[col for col in train.columns if col != 'genre']]\n",
    "y_train = train['genre']\n",
    "gSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search Best Model and Feature Importance for Track Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71375"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find feature importance\n",
    "gSearch.best_score_\n",
    "my_feature_importance = gSearch.best_estimator_.feature_importances_\n",
    "features = [col for col in train.columns if col != 'genre']\n",
    "# print out feature importances for feature optimization\n",
    "sorted(list(zip(features, my_feature_importance)), key = lambda x: -x[1])\n",
    "#gSearch.best_estimator_\n",
    "#gSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failure Analysis - Track Attributes Random Forest \n",
    "Failure analysis is conducted by calculating the mean track for each genre.\n",
    "The euclidean distance is used to show that tracks that are incorrectly classified\n",
    "are on average further away from the mean track than correctly classified tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mean song for each genre\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "# step 1 group by genre\n",
    "mean_track_df = train.groupby('genre').mean().reset_index()\n",
    "\n",
    "# start failure analysis for random forest\n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "# train models\n",
    "rf_clf = train_random_forest(train)\n",
    "X_test = test[[col for col in test.columns if col != 'genre']]\n",
    "y_test = test['genre']\n",
    "# predict the genres using the X_test feature values.\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# create a failure df to store the predicted genre, true genre\n",
    "failure_df = pd.DataFrame()\n",
    "failure_df['true_y'] = y_test\n",
    "failure_df['pred_y'] = y_pred_rf\n",
    "# pull in feature values for distance calculation.\n",
    "failure_df[[col for col in test.columns if col != 'genre']] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, 'alt-rock']\n",
      "94 92\n",
      "[False, 'classical']\n",
      "0 185\n",
      "[True, 'country']\n",
      "55 152\n",
      "[True, 'edm']\n",
      "75 133\n",
      "[True, 'heavy-metal']\n",
      "33 170\n",
      "[False, 'hip-hop']\n",
      "61 149\n",
      "[True, 'latin']\n",
      "58 143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024, 376)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_to_collect = ('alt-rock','classical', 'country',\n",
    "                       'edm', 'heavy-metal',  'hip-hop',\n",
    "                       'latin')\n",
    "required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo',\n",
    "                'duration_ms'\n",
    "            ]\n",
    "# assign a results column to show if the model predicted the genre correctly\n",
    "failure_df['results'] = (failure_df['pred_y'] == failure_df['true_y'])\n",
    "for genre in genres_to_collect:\n",
    "    # filter by unique genre\n",
    "    tempDF = failure_df[failure_df['true_y']==genre]\n",
    "    tempMean = mean_track_df[mean_track_df['genre']==genre]\n",
    "    # calcualte genre between mean track and every track with that genre\n",
    "    temp_sim = euclidean_distances(tempMean[required_cols], tempDF[required_cols])\n",
    "    sim_results = list(zip(temp_sim.flatten(), tempDF['results']))\n",
    "    # filter by correctly and incorrectly classifications\n",
    "    failures = [dis for (dis, status) in sim_results if status == False]\n",
    "    passes = [dis for (dis, status) in sim_results if status == True]\n",
    "    # evaluate if the mean distance is greater for failures or for passes\n",
    "    print([(np.mean(failures) > np.mean(passes)), genre])\n",
    "    print(len(failures), len(passes))\n",
    "# print the length of number of passes and fails in the entire dataset\n",
    "len(failure_df[failure_df['results']==True]), len(failure_df[failure_df['results']==False])      \n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "b78c5f28-75f3-4d35-9c8f-11dd9693160f",
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
