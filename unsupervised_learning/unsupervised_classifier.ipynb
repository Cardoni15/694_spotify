{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "cell_id": "3cd227f0-c6eb-4cbb-9124-00a02eb9d4b0",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "owner_user_id": "7cc5a0be-055b-40bf-ac0a-3dbaf638d522",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start writing code here...\n",
    "# The goal of this notebook is to lay the foundation\n",
    "# for two types of supervised machine learning classifiers.\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_raw_data(raw_df):\n",
    "    \"\"\"\n",
    "    Consume a dataframe\n",
    "\n",
    "    Return a DF with the musical attributes and genre columns only\n",
    "    \"\"\"\n",
    "    # rename artist genres to be called genre\n",
    "    raw_df.rename(columns={'artist_genres': 'genre'}, inplace=True)\n",
    "    # features and y val cols.\n",
    "    required_cols = ['danceability', 'energy', 'key', 'loudness', 'mode', \n",
    "                'speechiness', 'acousticness', 'instrumentalness', \n",
    "                'liveness', 'valence', 'tempo', 'time_signature',\n",
    "                'duration_ms', 'genre'\n",
    "       ]\n",
    "    # remove unneccessary cols\n",
    "    raw_df = raw_df[required_cols]\n",
    "    return raw_df\n",
    "def generate_train_test(tracks_df, random_val=42, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        a dataframe containing song attributes and genre.\n",
    "        random val for repeatability\n",
    "        split_ratio = decimal pct of samples to use for training.\n",
    "    returns:\n",
    "        two dataframes train_df and test_df\n",
    "    \"\"\"\n",
    "    # step 1 shuffle the df\n",
    "    temp_df = tracks_df.sample(random_state=random_val, frac=1.0)\n",
    "    # establish a number to split the frame at.\n",
    "    num_train_samples = int(split_ratio*len(tracks_df))\n",
    "    # split the DF into two sets train and test\n",
    "    return np.split(temp_df, [num_train_samples])\n",
    "# PCA\n",
    "# goal apply PCA to the data set. Evaluate impact on F1\n",
    "def apply_pca(train_df, test_df, n_dim = 2):\n",
    "    \"\"\"\n",
    "    read in the training data for a dataframe\n",
    "    apply dimmensionality reduction\n",
    "\n",
    "    return modified train and test sets\n",
    "    \"\"\"\n",
    "    # start off with stock settings\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    train_df.reset_index(inplace=True, drop=True)\n",
    "    test_df.reset_index(inplace=True, drop=True)\n",
    "    X_cols = [col for col in train_df.columns if col != 'genre']\n",
    "    myScaler = StandardScaler()\n",
    "    X_train = myScaler.fit_transform(train_df[X_cols])\n",
    "    X_test = myScaler.transform(test_df[X_cols])\n",
    "    # only use the training data to fit the pca model\n",
    "    pca.fit(X_train)\n",
    "    # lesson learned here you need to reset the index so that pandas merges the labels\n",
    "    # back in correctly\n",
    "    pca_train_df = pd.DataFrame(pca.transform(X_train))\n",
    "    pca_train_df['genre'] = train_df['genre']\n",
    "\n",
    "    pca_test_df = pd.DataFrame(pca.transform(X_test))\n",
    "    pca_test_df['genre'] = test_df['genre']\n",
    "    return pca_train_df, pca_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans_cluster(train, num_clusses=7):\n",
    "    X_train = train[[col for col in train.columns if col != 'genre']]\n",
    "    y_train = train['genre']\n",
    "\n",
    "    km = KMeans(n_clusters=num_clusses, random_state=42)\n",
    "    km.fit(X_train)\n",
    "    # label the clusters using most frequent\n",
    "    clus = km.predict(X_train)\n",
    "    num_1 = []\n",
    "    # create a dictionary that will store a map of cluster labels to its most frequent\n",
    "    # genre label\n",
    "    clust_dict = defaultdict(str)\n",
    "    for tc in range(num_clusses):\n",
    "        temp_clusts = [y_train.values[i] for i in range(len(y_train)) if clus[i]==tc]\n",
    "        if Counter(temp_clusts).most_common(1):\n",
    "            num_1.append(Counter(temp_clusts).most_common(1)[0][0])\n",
    "            clust_dict[tc] = Counter(temp_clusts).most_common(1)[0][0]\n",
    "    return km, clust_dict\n",
    "\n",
    "def test_kmeans_cluster(km, clust_dict, test):\n",
    "    \"\"\"\n",
    "    provide a fitted kmeans cluster model\n",
    "    a dictionary mapping clusters to labels\n",
    "    test data\n",
    "\n",
    "    return f1 score for model\n",
    "    \"\"\"\n",
    "    X_test = test[[col for col in train.columns if col != 'genre']]\n",
    "    y_test = test['genre']\n",
    "    preds = km.predict(X_test)\n",
    "    preds = [clust_dict[cl] for cl in preds]\n",
    "    return f1_score(y_test, preds, average='macro')\n",
    "#Counter(num_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.429790830295275"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data \n",
    "raw_df = pd.read_csv('../raw_spotify_data/pure_genre_data.csv')\n",
    "clean_df = condition_raw_data(raw_df)\n",
    "train, test = generate_train_test(clean_df, 42, 0.8)\n",
    "train, test = apply_pca(train, test, 2)\n",
    "km, clust_dict = train_kmeans_cluster(train, num_clusses=20)\n",
    "test_kmeans_cluster(km, clust_dict, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=659c715d-e2b5-478e-9116-4d32a5174810' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "3cc889a5-e88f-4baf-a25c-28e0d2504d8d",
  "interpreter": {
   "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
